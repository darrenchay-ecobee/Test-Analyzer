{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries for data retrieval\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "# Importing libraries for data processing\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "TOKEN = os.getenv(\"TOKEN\")\n",
    "\n",
    "if TOKEN is None:\n",
    "    raise ValueError(\"TOKEN environment variable is not set. Please set it in the .env file.\")\n",
    "\n",
    "OWNER = os.getenv(\"OWNER\")\n",
    "REPO = os.getenv(\"REPO\")\n",
    "START_TIME = os.getenv(\"START_TIME\")\n",
    "END_TIME = os.getenv(\"END_TIME\")\n",
    "DESTINATION_DIR_ZIPS = os.getenv(\"DESTINATION_DIR_ZIPS\")\n",
    "DESTINATION_DIR_DATA = os.getenv(\"DESTINATION_DIR_DATA\")\n",
    "WORKFLOW_ID = os.getenv(\"WORKFLOW_ID\")\n",
    "\n",
    "# Create the destination directories if they don't exist\n",
    "os.makedirs(DESTINATION_DIR_ZIPS, exist_ok=True)\n",
    "os.makedirs(DESTINATION_DIR_DATA, exist_ok=True)\n",
    "\n",
    "# Ensure the destination directories are writable\n",
    "os.chmod(DESTINATION_DIR_ZIPS, 0o777)\n",
    "os.chmod(DESTINATION_DIR_DATA, 0o777)\n",
    "\n",
    "# Fetch all workflow runs for the specified workflow\n",
    "url = f\"https://api.github.com/repos/{OWNER}/{REPO}/actions/workflows/{WORKFLOW_ID}/runs\"\n",
    "headers = {\"Authorization\": f\"token {TOKEN}\"}\n",
    "response = requests.get(url, headers=headers)\n",
    "response.raise_for_status()  # Raise an exception for failed requests\n",
    "\n",
    "# Extract run IDs from the JSON response, filtering by the time range\n",
    "runs = response.json()[\"workflow_runs\"]\n",
    "run_ids = [run[\"id\"] for run in runs if START_TIME <= run[\"created_at\"] <= END_TIME]\n",
    "\n",
    "# Check if any runs are found in the time range\n",
    "if not run_ids:\n",
    "    print(\"No runs found in the specified time range.\")\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the data\n",
    "def parse_test_report(file_path: str) -> ET.Element:\n",
    "    tree = ET.parse(file_path)\n",
    "    return tree.getroot()\n",
    "\n",
    "# Create a test data object for each file\n",
    "def extract_test_data(root: ET.Element) -> list:\n",
    "    test_data = []\n",
    "    for testcase in root.findall('testcase'):\n",
    "        name = testcase.attrib.get('name')\n",
    "        classname = testcase.attrib.get('classname')\n",
    "        time = float(testcase.attrib.get('time', 0))\n",
    "        failure = testcase.find('failure') is not None\n",
    "        error = testcase.find('error') is not None\n",
    "        test_data.append({\n",
    "            'name': name,\n",
    "            'classname': classname,\n",
    "            'time': time,\n",
    "            'failure': failure,\n",
    "            'error': error\n",
    "        })\n",
    "    return test_data\n",
    "\n",
    "# Extracts the data from all files and returns in list form for analysis\n",
    "def collect_test_data(report_dir: str) -> list:\n",
    "    test_data = []\n",
    "    for root, _, files in os.walk(report_dir):\n",
    "        for file_name in files:\n",
    "            if file_name.endswith('.xml'):\n",
    "                file_path = os.path.join(root, file_name)\n",
    "                root_element = parse_test_report(file_path)\n",
    "                data = extract_test_data(root_element)\n",
    "                test_data.append(data)\n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieves the relevant info from the test data and creates a dataframe\n",
    "def analyze_test_data(test_data: list) -> pd.DataFrame:\n",
    "    test_runs = defaultdict(lambda: {'test_class': '','runs': 0, 'failures': 0, 'total_time': 0.0})\n",
    "\n",
    "    for run_data in test_data:\n",
    "        for test in run_data:\n",
    "            test_name = f\"{test['name']}\"\n",
    "            test_runs[test_name]['runs'] += 1\n",
    "            test_runs[test_name]['test_class'] = test['classname']\n",
    "            test_runs[test_name]['total_time'] += test['time']\n",
    "            if test['failure'] or test['error']:\n",
    "                test_runs[test_name]['failures'] += 1\n",
    "\n",
    "    # Create a DataFrame\n",
    "    test_data_df = pd.DataFrame([\n",
    "        {'test_name': test_name, 'test_class': counts['test_class'], 'runs': counts['runs'], 'failures': counts['failures'], 'total_time': counts['total_time']}\n",
    "        for test_name, counts in test_runs.items()\n",
    "    ])\n",
    "\n",
    "    # Calculate failure percentage for each test\n",
    "    test_data_df['failure_percentage'] = (test_data_df['failures'] / test_data_df['runs']) * 100\n",
    "\n",
    "    # Threshold percentage for flakiness\n",
    "    threshold_percentage = 5  # Adjust as needed\n",
    "\n",
    "    # Mark a test as flakey if failure percentage is > threshold\n",
    "    test_data_df['flakey'] = test_data_df['failure_percentage'] > threshold_percentage\n",
    "    test_data_df['avg_time'] = test_data_df['total_time'] / test_data_df['runs']\n",
    "\n",
    "    return test_data_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading artifact from run 9230076215...\n",
      "Downloading artifact from run 9229325430...\n",
      "Downloading artifact from run 9228854308...\n",
      "Downloading artifact from run 9228844573...\n",
      "Downloading artifact from run 9227814266...\n",
      "Downloading artifact from run 9227761562...\n",
      "Downloading artifact from run 9227646644...\n",
      "Downloading artifact from run 9227619728...\n",
      "Downloading artifact from run 9227412392...\n",
      "Downloading artifact from run 9224550252...\n",
      "Downloading artifact from run 9216290803...\n",
      "Downloading artifact from run 9216251934...\n",
      "Downloading artifact from run 9216153854...\n",
      "All artifacts downloaded and extracted successfully.\n"
     ]
    }
   ],
   "source": [
    "# Retrieving data\n",
    "test_data = []\n",
    "\n",
    "# Loop through each workflow run\n",
    "for run_id in run_ids:\n",
    "    print(f\"Downloading artifacts from run {run_id}...\")\n",
    "\n",
    "    # Get artifacts for the current run\n",
    "    url = f\"https://api.github.com/repos/{OWNER}/{REPO}/actions/runs/{run_id}/artifacts\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    response.raise_for_status()  # Raise an exception for failed requests\n",
    "    \n",
    "    # Extract artifact URLs and names from the JSON response\n",
    "    artifacts = response.json()[\"artifacts\"]\n",
    "    for artifact in artifacts:\n",
    "        if \"Test Results\" in artifact[\"name\"]:\n",
    "            artifact_name = artifact[\"name\"]\n",
    "            artifact_url = artifact[\"archive_download_url\"]\n",
    "\n",
    "            # Download the artifact to the zips folder\n",
    "            filename = f\"{artifact_name}.zip\"\n",
    "            zip_path = os.path.join(DESTINATION_DIR_ZIPS, filename)\n",
    "            response = requests.get(artifact_url, headers=headers)\n",
    "            response.raise_for_status()  # Raise an exception for failed requests\n",
    "            with open(zip_path, \"wb\") as f:\n",
    "                f.write(response.content)\n",
    "\n",
    "            # Create a folder for unzipped artifact\n",
    "            artifact_dir = os.path.join(DESTINATION_DIR_DATA, artifact_name)\n",
    "            os.makedirs(artifact_dir, exist_ok=True)\n",
    "\n",
    "            # Ensure the directory is writable\n",
    "            os.chmod(artifact_dir, 0o777)\n",
    "\n",
    "            # Unzip the artifact\n",
    "            with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "                zip_ref.extractall(artifact_dir)\n",
    "\n",
    "            # Load data to list\n",
    "            test_data.append(collect_test_data(report_dir=\"./temp\"))\n",
    "            \n",
    "            # Delete the zip and extracted files after unzipping to prevent storage from filling up\n",
    "            os.remove(zip_path)\n",
    "            shutil.rmtree(artifact_dir)\n",
    "\n",
    "print(\"All artifacts downloaded and extracted successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing and analyzing data\n",
    "all_test_data = []\n",
    "for test_data_run in test_data:\n",
    "    all_test_data.extend(test_data_run)\n",
    "\n",
    "test_data_df = analyze_test_data(all_test_data)\n",
    "# Display the DataFrame\n",
    "display(test_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeing all parts of repo which contains tests\n",
    "def get_class_mapping(row):\n",
    "    classname = row['test_class'].split('.')[2]\n",
    "    return classname\n",
    "test_data_df['class_location'] = test_data_df.apply(get_class_mapping, axis=1)\n",
    "display(test_data_df['class_location'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding github link for each test\n",
    "\n",
    "folder_class_map = { # Did some for now\n",
    "    \"foundation\": \"foundation/test/source\",\n",
    "    # \"cache\": \"lib-cache\",\n",
    "    \"communicator\": \"communicator/test/source\",\n",
    "    \"ests\": \"ests-pubsub/src/test/java\",\n",
    "    \"events\": \"lib-events/test/java\",\n",
    "    \"reportprocessor\": \"report-processor/src/test/java\",\n",
    "    \"webapp\": \"gui/test/src\",\n",
    "    \"contractorservice\": \"libs/communicator/contractor-service-client\",\n",
    "}\n",
    "\n",
    "# Base URL for the GitHub repository\n",
    "base_github_url = f\"https://github.com/{OWNER}/{REPO}/tree/main\"\n",
    "\n",
    "def create_github_link(row):\n",
    "    location = row['test_class'].split('.')[2]\n",
    "    # Replace dots in the class name with slashes to form the path\n",
    "    class_path = row['test_class'].replace('.', '/')\n",
    "    # Construct the GitHub URL\n",
    "    return f\"{base_github_url}/{folder_class_map.get(location)}/{class_path}.java\"\n",
    "\n",
    "# Add a column for GitHub links \n",
    "test_data_df['github_link'] = test_data_df.apply(create_github_link, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE\n",
    "Not all github links will work, just did the quickest approach to get the majority of links for ease of searching up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_time_tests = test_data_df.sort_values(by='avg_time', ascending=False).head(50)\n",
    "\n",
    "display(top_time_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flakey_tests = test_data_df[test_data_df['flakey']].sort_values(by='failure_percentage', ascending=False)\n",
    "display(flakey_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of flakey tests per class_location\n",
    "flakey_counts = test_data_df.groupby('class_location')['flakey'].sum().reset_index(name='flakey_count')\n",
    "total_counts = test_data_df.groupby('class_location')['flakey'].count().reset_index(name='total_count')\n",
    "\n",
    "flakey_percentage_per_class = pd.merge(flakey_counts, total_counts, on='class_location')\n",
    "flakey_percentage_per_class['flakey_percentage'] = (flakey_percentage_per_class['flakey_count'] / flakey_percentage_per_class['total_count']) * 100\n",
    "\n",
    "# Calculate the average time per class_location\n",
    "avg_time_per_class = test_data_df.groupby('class_location')['avg_time'].mean().reset_index()\n",
    "\n",
    "# Merge the two DataFrames\n",
    "class_metrics_df = pd.merge(flakey_percentage_per_class, avg_time_per_class, on='class_location')\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "# Plot flakey percentage\n",
    "sns.barplot(x='flakey_percentage', y='class_location', data=class_metrics_df.sort_values('flakey_percentage', ascending=False), ax=ax[0])\n",
    "ax[0].set_title('Class Locations with Highest Percentage of Flakey Tests')\n",
    "ax[0].set_xlabel('Flakey Percentage')\n",
    "ax[0].set_ylabel('Class Location')\n",
    "\n",
    "# Plot average time\n",
    "sns.barplot(x='avg_time', y='class_location', data=class_metrics_df.sort_values('avg_time', ascending=False), ax=ax[1])\n",
    "ax[1].set_title('Class Locations with Highest Average Time')\n",
    "ax[1].set_xlabel('Average Time (s)')\n",
    "ax[1].set_ylabel('Class Location')\n",
    "\n",
    "# Rotate class location labels for better readability\n",
    "for axis in ax:\n",
    "    for label in axis.get_yticklabels():\n",
    "        label.set_rotation(0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This above is just a quick attempt to see if there is a way to graph the data and see which areas are the biggest pain points right now in terms of time and flakeyness (probably needs to be better processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data\n",
    "test_data_df.to_csv('test_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
